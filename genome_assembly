# 1) Long read quality control

./fastqc *fastq.gz fastqc_output/

# 2) Run Supernova

supernova run \--id=SFS_longreadassembly \--fastqs=/home/jesse/vol1/NQA6UAY/WIL14931.20201014/201007_E00389_0476_AHF2MTCCX2/working/supernova-2.1.1/SFS_fastq \--maxreads='all'

# 3) Make fasta (style raw) from supernova run

nohup supernova mkoutput \
        --style=raw \
        --asmdir=SFS_longreadassembly/outs/assembly \
        --outprefix=SFS_longreadassembly/fasta_raw & 
        [ --minsize=N ] \
        [ --headers=short|full ]

# 4) Short read quality control

./fastqc *fastq.gz fastqc_output/

# 5) Concatenate short reads across lanes and re run fastqc

nohup cat SFS_CC1_S14_L*_R1_001.fastq.gz > SFS_CC1_R1.fastq.gz & 
nohup cat SFS_CC1_S14_L*_R2_001.fastq.gz > SFS_CC1_R2.fastq.gz &

# 6) Trim using trimmomatic
nohup java -jar /home/jesse/vol1/NQA6UAY/WIL14931.20201014/201007_E00389_0476_AHF2MTCCX2/working/Trimmomatic-0.39/trimmomatic-0.39.jar PE SFS_CC1_R1.fastq.gz SFS_CC1_R2.fastq.gz SFS_CC1_R1_Trimmed.fastq.gz SFS_CC1_R1_Unpaired.fastq.gz SFS_CC1_R2_Trimmed.fastq.gz SFS_CC1_R2_Unpaired.fastq.gz ILLUMINACLIP:/home/jesse/vol1/NQA6UAY/WIL14931.20201014/201007_E00389_0476_AHF2MTCCX2/working/Trimmomatic-0.39/adapters/TruSeq3-PE-2.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 &

# 7) Contamination classification with kraken2 - run for each short-read pair separately and make sure to generate reports -> generate custom bacteria only db ***output is fastq NOT fastq.gz

#Kraken db build
kraken2-build --download-taxonomy --db bacteriaDB
kraken2-build --download-library bacteria --db bacteriaDB
nohup kraken2-build --build --db bacteriaDB &

# kraken classification
nohup /home/ubuntu/volume_genome/NLDN8JR/WIL14931/200929_E00389_0474_AHCF7VCCX2/working/kraken2-2.1.1/kraken2_dir/kraken2 --gzip-compressed --db /home/ubuntu/volume_genome/NLDN8JR/WIL14931/200929_E00389_0474_AHCF7VCCX2/working/kraken2-2.1.1/kraken2_dir/bacteriaDB --paired --unclassified-out NFS_50254_unclass#.fastq.gz SFS_CC1_R1_Trimmed.fastq.gz SFS_CC1_R2_Trimmed.fastq.gz --report SFS_CC1Report --use-names &

# Count number of reads after trimming and contamination screening
cat file.fastq | paste - - - - | cut -f2 | wc -c > file_* (* = 1 or 2 depending on forward/reverse)

# 8) kmer genie
nohup ./kmergenie list_file & 
# Need to re-run with higher K 
nohup ./kmergenie -k 200 list_file & 

# 9) meraculous installation +assembly ########### DID NOT END UP USING FOR MS ###############
# Dependencies = cmake >= 2.8, GCC g++ >= 4.4.7, GNU make 3.81, Boost C++ library >= 1.50.0, Perl (>= 5.10), Log4perl.pm (>= 1.31), gnuplot (>= 3.7)

# 9) Start run

# 9.1) Import step - runs on 2 cores with 4GB of RAM
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -archive -step -cleanup_level 1 -dir meraculous_16core_Jan13 &

# 9.2) Mercount step - takes ~23 hours on 16 core with 64 GB RAM
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -archive -step -cleanup_level 1 -start meraculous_mercount -restart -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &

# 9.3) Mergraph stage - takes ~30 hours on 16 cores with 64GB RAM
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -archive -step -cleanup_level 1 -start meraculous_mergraph -restart -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &

# 9.4) UFX stage - runs on 2 cores with 4GB of RAM
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -archive -step -cleanup_level 1 -start meraculous_ufx -restart -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &

# 9.5) Contigs stage - takes ~3 hours on 32 cores with 256GB of RAM
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -archive -step -cleanup_level 1 -start meraculous_contigs -restart -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &

# 9.6) bubble
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -archive -step -cleanup_level 1 -start meraculous_bubble -restart -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &
# crashed part way as exceeded 16 core 64GB of RAM @ bubblemap stage, took another hour with 126GB RAM -> had to change bubble_depth_threshold to 1 in meraculous.config2
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -step -cleanup_level 1 -resume -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &

9.7) merblast - 27.5 hours on 16 cores with 128GB ram (could have went to 64GB)
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -archive -step -cleanup_level 1 -start meraculous_merblast -restart -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &

9.8) ono
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -archive -step -cleanup_level 1 -start meraculous_ono -restart -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &
#crashed after running for a few hours on the 24/7 - resume on 16 core 64GB, took ~4 hours

9.9) gap_closure 
# crashed twice - once at 64gb and once after 4.5 hrs on 128gb
# took 6.5 hours with 32 cores and 256 GB
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -step -cleanup_level 1 -resume -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &

9.10) meraculous_final_results
# crashed on 2 cores 4GB, took 15 min with 32gb and 16 cores
nohup bash /home/ubuntu/Meraculous-v2.2.6/build/bin/run_meraculous.sh -c meraculous.config2 -archive -step -cleanup_level 1 -start meraculous_final_results -restart -dir /home/ubuntu/vol1/meraculous_16core_Jan13 &


#10) BUSCO on long read asssembly
# took 13 hours with 8 cores 16gb ram
export BUSCO_CONFIG_FILE=./config/config.ini
export PATH=$PATH:/usr/bin/augustus
export AUGUSTUS_CONFIG_PATH=//home/ubuntu/vol1/busco/augustus-3.3.2/config
nohup scripts/run_BUSCO.py -i ./fasta_pseudohap.fasta -o fasta_pseudohap_BUSCO -l mammalia_odb9 -m geno -f -sp human -c 2 &

#11) Repeat Masker


#12) Annotation with AUGUSTUS
